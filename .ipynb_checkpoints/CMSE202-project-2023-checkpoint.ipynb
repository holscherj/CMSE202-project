{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ce93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful / Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a2af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV and drop rows that are from older years\n",
    "# in order to make the dataset more manageable and current.\n",
    "# Only dropping rows from 2016/17, and this cell should only need\n",
    "# to be run one time to create the cleaned data file.\n",
    "\n",
    "with open('US_Accidents_Dec21_updated.csv', 'r') as inp, open('accidents_cleaned.csv', 'w') as out:\n",
    "    writer = csv.writer(out)\n",
    "    reader = csv.reader(inp)\n",
    "    \n",
    "    # skip the header row\n",
    "    writer.writerow(next(reader))\n",
    "    \n",
    "    for row in reader:\n",
    "        if \"2021\" in row[2] or \"2020\" in row[2] or \"2019\" in row[2] or \"2018\" in row[2]:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42530bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, this cell might take a minute to finish\n",
    "# execution due to large size of the csv file.\n",
    "accidents = pd.read_csv(\"accidents_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cdd2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset by dropping unnecessary columns\n",
    "drop = [\"Start_Lat\", \"Start_Lng\", \"End_Lat\", \"End_Lng\",\n",
    "        \"Timezone\", \"Airport_Code\", \"Number\", \"Description\"]\n",
    "\n",
    "accidents.drop(columns=drop, inplace=True)\n",
    "\n",
    "# Convert time columns to datetime formats\n",
    "accidents['Start_Time'] = pd.to_datetime(accidents['Start_Time'])\n",
    "accidents['End_Time'] = pd.to_datetime(accidents['End_Time'])\n",
    "accidents['Weather_Timestamp'] = pd.to_datetime(accidents['Weather_Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7256d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Examine Data for Cleaning -----------------------\n",
      "\n",
      "Data types for each column in the dataset:\n",
      "ID                               object\n",
      "Severity                          int64\n",
      "Start_Time               datetime64[ns]\n",
      "End_Time                 datetime64[ns]\n",
      "Distance(mi)                    float64\n",
      "Street                           object\n",
      "Side                             object\n",
      "City                             object\n",
      "County                           object\n",
      "State                            object\n",
      "Zipcode                          object\n",
      "Country                          object\n",
      "Weather_Timestamp        datetime64[ns]\n",
      "Temperature(F)                  float64\n",
      "Wind_Chill(F)                   float64\n",
      "Humidity(%)                     float64\n",
      "Pressure(in)                    float64\n",
      "Visibility(mi)                  float64\n",
      "Wind_Direction                   object\n",
      "Wind_Speed(mph)                 float64\n",
      "Precipitation(in)               float64\n",
      "Weather_Condition                object\n",
      "Amenity                            bool\n",
      "Bump                               bool\n",
      "Crossing                           bool\n",
      "Give_Way                           bool\n",
      "Junction                           bool\n",
      "No_Exit                            bool\n",
      "Railway                            bool\n",
      "Roundabout                         bool\n",
      "Station                            bool\n",
      "Stop                               bool\n",
      "Traffic_Calming                    bool\n",
      "Traffic_Signal                     bool\n",
      "Turning_Loop                       bool\n",
      "Sunrise_Sunset                   object\n",
      "Civil_Twilight                   object\n",
      "Nautical_Twilight                object\n",
      "Astronomical_Twilight            object\n",
      "dtype: object\n",
      "\n",
      "Number of duplicated rows in the dataset:\n",
      "0\n",
      "\n",
      "Number of null values in the dataset:\n",
      "ID                            0\n",
      "Severity                      0\n",
      "Start_Time                    0\n",
      "End_Time                      0\n",
      "Distance(mi)                  0\n",
      "Street                        2\n",
      "Side                          0\n",
      "City                        109\n",
      "County                        0\n",
      "State                         0\n",
      "Zipcode                    1134\n",
      "Country                       0\n",
      "Weather_Timestamp         47727\n",
      "Temperature(F)            63006\n",
      "Wind_Chill(F)            226978\n",
      "Humidity(%)               66518\n",
      "Pressure(in)              53976\n",
      "Visibility(mi)            63201\n",
      "Wind_Direction            70744\n",
      "Wind_Speed(mph)          108193\n",
      "Precipitation(in)        297283\n",
      "Weather_Condition         63278\n",
      "Amenity                       0\n",
      "Bump                          0\n",
      "Crossing                      0\n",
      "Give_Way                      0\n",
      "Junction                      0\n",
      "No_Exit                       0\n",
      "Railway                       0\n",
      "Roundabout                    0\n",
      "Station                       0\n",
      "Stop                          0\n",
      "Traffic_Calming               0\n",
      "Traffic_Signal                0\n",
      "Turning_Loop                  0\n",
      "Sunrise_Sunset             2839\n",
      "Civil_Twilight             2839\n",
      "Nautical_Twilight          2839\n",
      "Astronomical_Twilight      2839\n",
      "dtype: int64\n",
      "\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Examine the dataset to determine if it needs to be cleaned in any way.\n",
    "# We are looking for duplicate rows, NaN/null values, and incorrect data types.\n",
    "\n",
    "print(\"----------------------- Examine Data for Cleaning -----------------------\")\n",
    "print()\n",
    "\n",
    "# Starting with data types...\n",
    "print(\"Data types for each column in the dataset:\")\n",
    "print(accidents.dtypes)\n",
    "print()\n",
    "\n",
    "# Duplicate rows\n",
    "print(\"Number of duplicated rows in the dataset:\")\n",
    "print(accidents.duplicated().sum())\n",
    "print()\n",
    "\n",
    "# Null values\n",
    "print(\"Number of null values in the dataset:\")\n",
    "print(accidents.isnull().sum())\n",
    "\n",
    "print()\n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f8aa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in the dataset:\n",
      "ID                       0\n",
      "Severity                 0\n",
      "Start_Time               0\n",
      "End_Time                 0\n",
      "Distance(mi)             0\n",
      "Street                   0\n",
      "Side                     0\n",
      "City                     0\n",
      "County                   0\n",
      "State                    0\n",
      "Zipcode                  0\n",
      "Country                  0\n",
      "Weather_Timestamp        0\n",
      "Temperature(F)           0\n",
      "Wind_Chill(F)            0\n",
      "Humidity(%)              0\n",
      "Pressure(in)             0\n",
      "Visibility(mi)           0\n",
      "Wind_Direction           0\n",
      "Wind_Speed(mph)          0\n",
      "Precipitation(in)        0\n",
      "Weather_Condition        0\n",
      "Amenity                  0\n",
      "Bump                     0\n",
      "Crossing                 0\n",
      "Give_Way                 0\n",
      "Junction                 0\n",
      "No_Exit                  0\n",
      "Railway                  0\n",
      "Roundabout               0\n",
      "Station                  0\n",
      "Stop                     0\n",
      "Traffic_Calming          0\n",
      "Traffic_Signal           0\n",
      "Turning_Loop             0\n",
      "Sunrise_Sunset           0\n",
      "Civil_Twilight           0\n",
      "Nautical_Twilight        0\n",
      "Astronomical_Twilight    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Continue to clean the dataset by removing rows with missing values\n",
    "# Drop rows with null values, using column names printed above\n",
    "accidents.dropna(subset = ['Street', 'City', 'Zipcode', 'Weather_Timestamp', 'Temperature(F)',\n",
    "                    'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
    "                    'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition',\n",
    "                    'Sunrise_Sunset', 'Civil_Twilight', \"Nautical_Twilight\", \"Astronomical_Twilight\"],\n",
    "                 inplace = True)\n",
    "\n",
    "# Now reprint the count of null values\n",
    "print(\"Number of null values in the dataset:\")\n",
    "print(accidents.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c456e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the cleaning process yet again by converting the catagorical\n",
    "# variables in the dataset into integer values so that they can run in\n",
    "# the regression model that we will create\n",
    "LE = LabelEncoder()\n",
    "accidents = accidents.apply(LE.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43c06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the data is cleaned, we can start building the regression model\n",
    "\n",
    "# Using a logistic regression model from the statsmodels api will allow\n",
    "# us to determine which features are most effective at making predictions\n",
    "# about the servarity of an accident.\n",
    "\n",
    "# Split the dataset into testing and training data\n",
    "# We can ignore the ID since it won't have any weight\n",
    "# on the decision maxing process\n",
    "features = [\"Start_Time\", \"End_Time\", \"Distance(mi)\", \"Street\", \"Side\", \"City\",\n",
    "            \"County\", \"State\", \"Zipcode\", \"Country\", \"Weather_Timestamp\",\n",
    "            \"Temperature(F)\", \"Wind_Chill(F)\", \"Humidity(%)\",\n",
    "            \"Pressure(in)\", \"Visibility(mi)\", \"Wind_Direction\", \"Wind_Speed(mph)\",\n",
    "            \"Precipitation(in)\", \"Weather_Condition\", \"Amenity\", \"Bump\", \"Crossing\",\n",
    "            \"Give_Way\", \"Junction\", \"No_Exit\", \"Railway\", \"Roundabout\", \"Station\",\n",
    "            \"Stop\", \"Traffic_Calming\", \"Traffic_Signal\", \"Turning_Loop\", \"Sunrise_Sunset\",\n",
    "            \"Civil_Twilight\", \"Nautical_Twilight\", \"Astronomical_Twilight\"]\n",
    "\n",
    "X = accidents.loc[:, features]\n",
    "y = accidents.loc[:, 'Severity']\n",
    "\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(X, y, random_state=123, train_size=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02db41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Severity   R-squared:                       0.077\n",
      "Model:                            OLS   Adj. R-squared:                  0.077\n",
      "Method:                 Least Squares   F-statistic:                     3900.\n",
      "Date:                Tue, 18 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        04:11:59   Log-Likelihood:            -6.7101e+05\n",
      "No. Observations:             1647273   AIC:                         1.342e+06\n",
      "Df Residuals:                 1647237   BIC:                         1.343e+06\n",
      "Df Model:                          35                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     1.6823      0.005    355.813      0.000       1.673       1.692\n",
      "Start_Time             8.083e-07   2.76e-08     29.257      0.000    7.54e-07    8.62e-07\n",
      "End_Time               3.307e-07   1.57e-08     21.113      0.000       3e-07    3.61e-07\n",
      "Distance(mi)           2.412e-05   2.47e-07     97.728      0.000    2.36e-05    2.46e-05\n",
      "Street                -2.805e-07   8.94e-09    -31.355      0.000   -2.98e-07   -2.63e-07\n",
      "Side                     -0.0107      0.001    -13.087      0.000      -0.012      -0.009\n",
      "City                  -2.519e-06   1.11e-07    -22.778      0.000   -2.74e-06    -2.3e-06\n",
      "County                -2.329e-05   7.82e-07    -29.792      0.000   -2.48e-05   -2.18e-05\n",
      "State                  7.674e-05   2.14e-05      3.593      0.000    3.49e-05       0.000\n",
      "Zipcode               -5.321e-07   3.56e-09   -149.461      0.000   -5.39e-07   -5.25e-07\n",
      "Country                1.317e-14   1.13e-15     11.610      0.000    1.09e-14    1.54e-14\n",
      "Weather_Timestamp     -7.157e-06    4.8e-08   -149.095      0.000   -7.25e-06   -7.06e-06\n",
      "Temperature(F)            0.0005   2.91e-05     17.752      0.000       0.000       0.001\n",
      "Wind_Chill(F)            -0.0001   1.43e-05     -7.826      0.000      -0.000   -8.39e-05\n",
      "Humidity(%)               0.0005   1.53e-05     34.831      0.000       0.001       0.001\n",
      "Pressure(in)             -0.0002   2.89e-06    -69.803      0.000      -0.000      -0.000\n",
      "Visibility(mi)            0.0007   8.11e-05      8.270      0.000       0.001       0.001\n",
      "Wind_Direction           -0.0004   4.36e-05     -8.451      0.000      -0.000      -0.000\n",
      "Wind_Speed(mph)           0.0006   3.95e-05     15.787      0.000       0.001       0.001\n",
      "Precipitation(in)        -0.0002   7.34e-05     -3.340      0.001      -0.000      -0.000\n",
      "Weather_Condition     -8.676e-05   1.19e-05     -7.308      0.000      -0.000   -6.35e-05\n",
      "Amenity                   0.0131      0.003      4.689      0.000       0.008       0.019\n",
      "Bump                     -0.0043      0.023     -0.190      0.849      -0.049       0.040\n",
      "Crossing                 -0.0386      0.001    -31.667      0.000      -0.041      -0.036\n",
      "Give_Way                  0.0398      0.006      6.850      0.000       0.028       0.051\n",
      "Junction                  0.0326      0.001     30.730      0.000       0.031       0.035\n",
      "No_Exit                  -0.0082      0.007     -1.169      0.242      -0.022       0.006\n",
      "Railway                   0.0289      0.003      8.906      0.000       0.023       0.035\n",
      "Roundabout               -0.0480      0.040     -1.195      0.232      -0.127       0.031\n",
      "Station                  -0.0081      0.002     -4.478      0.000      -0.012      -0.005\n",
      "Stop                      0.0284      0.002     13.678      0.000       0.024       0.032\n",
      "Traffic_Calming           0.0306      0.018      1.688      0.091      -0.005       0.066\n",
      "Traffic_Signal           -0.0047      0.001     -4.370      0.000      -0.007      -0.003\n",
      "Turning_Loop          -7.708e-18   7.31e-18     -1.055      0.291    -2.2e-17    6.61e-18\n",
      "Sunrise_Sunset           -0.0035      0.001     -2.386      0.017      -0.006      -0.001\n",
      "Civil_Twilight           -0.0020      0.002     -1.027      0.304      -0.006       0.002\n",
      "Nautical_Twilight         0.0088      0.002      4.606      0.000       0.005       0.013\n",
      "Astronomical_Twilight     0.0040      0.002      2.653      0.008       0.001       0.007\n",
      "==============================================================================\n",
      "Omnibus:                  1178402.600   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         20254716.816\n",
      "Skew:                           3.329   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.836   Cond. No.                     1.13e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.38e-14. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Construct the model using the training labels and vectors\n",
    "# fit the model and print the summary so that we can evaluate\n",
    "# the different features based on their P scores\n",
    "ols_model = sm.OLS(train_labels, sm.add_constant(train_vectors))\n",
    "result = ols_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842c873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- Initial Evaluation -----------------------\n",
      "\n",
      "Precision: 0.8703468329524682\n",
      "Recall: 0.9329238087606448\n",
      "Accuracy: 0.9329238087606448\n",
      "\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now that we have an initial summary, we can drop factors that don't have much of\n",
    "# an affect on the correlation to the severity of an accident, as well as calculate\n",
    "# some basic statistics and metrics to determine the strength of the initial model\n",
    "\n",
    "# Remove the weak features and resplit the data.\n",
    "# Features being dropped are: Bump, No_Exit, Roundabout, Traffic_Calming,\n",
    "# Turning_Loop, and Civil_Twilight.\n",
    "features = [\"Start_Time\", \"End_Time\", \"Distance(mi)\", \"Street\", \"Side\",\n",
    "            \"City\", \"County\", \"State\", \"Zipcode\", \"Country\", \"Weather_Timestamp\",\n",
    "            \"Temperature(F)\", \"Wind_Chill(F)\", \"Humidity(%)\", \"Pressure(in)\",\n",
    "            \"Visibility(mi)\", \"Wind_Direction\", \"Wind_Speed(mph)\",\n",
    "            \"Precipitation(in)\", \"Weather_Condition\", \"Amenity\", \"Crossing\",\n",
    "            \"Give_Way\", \"Junction\", \"Railway\", \"Station\", \"Stop\", \"Traffic_Signal\",\n",
    "            \"Sunrise_Sunset\", \"Nautical_Twilight\", \"Astronomical_Twilight\"]\n",
    "\n",
    "X = accidents.loc[:, features]\n",
    "y = accidents.loc[:, 'Severity']\n",
    "\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(X, y, random_state=123, train_size=.75)\n",
    "\n",
    "# Reconstruct the model with the new data\n",
    "refined_ols_model = sm.OLS(train_labels, sm.add_constant(train_vectors))\n",
    "refined_result = refined_ols_model.fit()\n",
    "\n",
    "# Calculate the precision, recall and accuracy\n",
    "values = refined_result.predict(sm.add_constant(test_vectors))\n",
    "predictions = np.where(values > 0.5, 1, 0)\n",
    "\n",
    "p_score = precision_score(test_labels, predictions, average='weighted')\n",
    "r_score = recall_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "print(\"----------------------- Initial Evaluation -----------------------\\n\")\n",
    "print(f\"Precision: {p_score}\")\n",
    "print(f\"Recall: {r_score}\")\n",
    "\n",
    "correct = 0\n",
    "total_samples = len(test_labels)\n",
    "\n",
    "temp = np.array(test_labels)\n",
    "for i in range(len(test_labels)):\n",
    "    if predictions[i] == temp[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total_samples\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\n------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf23b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I temporarily commented these cells out because I don't have the 'cleaned.csv'\n",
    "# file that is used for the accidents_2 DataFrame\n",
    "\n",
    "# TODO: Recconcile tomorrow in class so I can make sure I have the right data\n",
    "\n",
    "# accidents_2 = pd.read_csv('cleaned.csv')\n",
    "# accidents_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de79e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding effect of time of day on the number of accidents\n",
    "\n",
    "# day_accidents = accidents[accidents['Sunrise_Sunset']=='Day']\n",
    "# night_accidents = accidents[accidents['Sunrise_Sunset']=='Night']\n",
    "\n",
    "# day_accidents_2 = accidents_2[accidents_2['Light_conditions']=='Daylight']\n",
    "# night_accidents_2 = accidents_2[accidents_2['Light_conditions']=='Darkness - lights lit'] + accidents_2[accidents_2['Light_conditions']=='Darkness - lights unlit'] + accidents_2[accidents_2['Light_conditions']=='Darkness - no lighting']\n",
    "\n",
    "# day_num = len(day_accidents)+len(day_accidents_2)\n",
    "# night_num = len(night_accidents)+len(night_accidents_2)\n",
    "# time_of_day =['Day', 'Night']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
